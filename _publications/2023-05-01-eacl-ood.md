---
title: "Improving Unsupervised Out-of-domain Detection through Pseudo Labeling and Learning"
collection: publications
category: manuscripts
permalink: /publication/2023-05-01-eacl-ood
excerpt: 'A novel two-stage framework for unsupervised out-of-domain detection that significantly outperforms baseline models through strategic pseudo labeling approaches.'
date: 2023-05-01
venue: 'Findings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (EACL)'
paperurl: 'https://aclanthology.org/2023.findings-eacl.76'
citation: 'Byounghan Lee, Jaesik Kim, Junekyu Park, Kyung-Ah Sohn. (2023). &quot;Improving Unsupervised Out-of-domain Detection through Pseudo Labeling and Learning.&quot; <i>Findings of the Association for Computational Linguistics: EACL 2023</i>, pages 1031â€“1041.'
---

We propose a novel two-stage framework for unsupervised out-of-domain (OOD) detection that addresses the limitations of traditional one-class classification approaches. Our method leverages pseudo labeling techniques to improve detection performance in challenging scenarios.

Unsupervised out-of-domain (OOD) detection is a task aimed at discriminating whether given samples are from the in-domain or not, without the categorical labels of in-domain instances. Unlike supervised OOD, as there are no labels for training a classifier, previous works on unsupervised OOD detection adopted the one-class classification (OCC) approach, assuming that the training samples come from a single class. However, this assumption is often violated in real-world scenarios where the training data contains multiple classes. Our empirical results on three datasets show that our two-stage framework significantly outperforms baseline models in more challenging scenarios.
